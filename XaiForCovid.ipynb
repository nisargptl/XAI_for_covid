{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeRbmq6WURft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eedacd7-8809-4fa9-bbbe-3f3d02a1f151"
      },
      "source": [
        "# Importing and installing important libraries\n",
        "\n",
        "!pip install lime\n",
        "!pip install Pillow\n",
        "!pip install shap\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image,ImageOps\n",
        "import torchvision\n",
        "from torch import optim,nn\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "# import shap\n",
        "import warnings\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# insert at 1, 0 is the script path (or '' in REPL)\n",
        "sys.path.insert(1, '/content/drive/MyDrive/xai/')\n",
        "from util_grad import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[K     |████████████████████████████████| 275 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.64.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (1.0.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.18.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=f8461541465e900ee241c39cad5d7b50571607f40caa3f9f035a066940a21c6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/cb/e5/ac701e12d365a08917bf4c6171c0961bc880a8181359c66aa7\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting shap\n",
            "  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.64.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.2)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.21.6)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>20.9->shap) (3.0.9)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.1.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.40.0 slicer-0.0.7\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Bb06B9oeAn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McWKY1yw4VQF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "930b182a-fd6b-4a19-e24d-e4220d3feb07"
      },
      "source": [
        "# Image augmentation\n",
        "\n",
        "fields = ['f_name','tag']\n",
        "with open('/content/drive/MyDrive/xai/archive/augmentation/aug_train_.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file,fieldnames = fields)\n",
        "    writer.writerows(pathos)\n",
        "labels = train_df['tag'].to_numpy()\n",
        "filenames = train_df['f_name']\n",
        "dataset = [[],[],[]]\n",
        "dir = [1,2,3]\n",
        "dir[0] = '/content/drive/MyDrive/xai/archive/augmentation/COVID-19_Radiography_Dataset/COVID/'\n",
        "dir[1] = '/content/drive/MyDrive/xai/archive/augmentation/COVID-19_Radiography_Dataset/Normal1/'\n",
        "dir[2] = '/content/drive/MyDrive/xai/archive/augmentation/COVID-19_Radiography_Dataset/Viral Pneumonia/'\n",
        "pathos = []\n",
        "k = 0\n",
        "l = ['COVID/','Normal1/','Viral Pneumonia/']\n",
        "for j in range(3):\n",
        "    my_images = os.listdir(dir[j])\n",
        "    for i in range(len(my_images)):\n",
        "        pathos.append([])\n",
        "        patho = l[j] + my_images[i]\n",
        "        pathos[k].append(patho)\n",
        "        pathos[k].append(j+1)\n",
        "        k+=1\n",
        "dir2 = ['/content/drive/MyDrive/augmented_images/covid','/content/drive/MyDrive/augmented_images/normal','/content/drive/MyDrive/augmented_images/pneumonia/']\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        brightness_range=[0.2,1.0],\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=False,\n",
        "        fill_mode='nearest')\n",
        "for k in range(3):\n",
        "  total = 5250 - len(dataset[k])\n",
        "  print(total)\n",
        "  cnt=0\n",
        "  b = total/len(dataset[k])\n",
        "  b = np.ceil(b)\n",
        "  print(b)\n",
        "  for j in range(len(dataset[k])):\n",
        "    i=0\n",
        "    for batch in datagen.flow(dataset[k][j], batch_size=1,\n",
        "                              save_to_dir=dir[k],\n",
        "                              save_prefix='aug',\n",
        "                              save_format='png'):\n",
        "        cnt+=1\n",
        "        i+=1\n",
        "        print(cnt)\n",
        "        if (i>b):\n",
        "\n",
        "          break\n",
        "    if(cnt>total):\n",
        "        print(k,len(dataset[k]))\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PermissionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cdd0eb6fc623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'f_name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/xai/archive/augmentation/aug_train_.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfieldnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: '/content/drive/MyDrive/xai/archive/augmentation/aug_train_.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdtFAkBQZBsG"
      },
      "source": [
        "# Loading and Preparing the dataset\n",
        "\n",
        "standard_normalization = transforms.Normalize((0.5), (0.5))\n",
        "data_transforms = transforms.Compose([transforms.RandomResizedCrop(256),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     standard_normalization])\n",
        "data_transforms_1 = transforms.Compose([transforms.RandomResizedCrop(256),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     standard_normalization])\n",
        "dict_ = {1:\"Covid\",2:\"Normal\",3:\"Viral Pneumonia\"}\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/xai/archive/augmentation/aug_train_.csv\")\n",
        "df = pd.concat([df,pd.get_dummies(df.tag)], axis=1)\n",
        "train, test = train_test_split(df,test_size=.2)\n",
        "train_, val = train_test_split(train,test_size=.2)\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "train_ = train_.reset_index(drop=True)\n",
        "val = val.reset_index(drop=True)\n",
        "from torch.utils.data import  WeightedRandomSampler\n",
        "class_freq = torch.tensor(train_.tag.values).bincount()\n",
        "weight = 1 / class_freq\n",
        "samples_weight = weight[train_.tag.values]\n",
        "sampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
        "root_dir = \"/content/drive/MyDrive/xai/archive/augmentation/COVID-19_Radiography_Dataset\"\n",
        "\n",
        "trainset = Xray_dataset(train,root_dir,transform = data_transforms)\n",
        "train_loader = DataLoader(trainset, batch_size=7, shuffle=True)\n",
        "\n",
        "testset = Xray_dataset(test,root_dir,transform = data_transforms_1)\n",
        "test_loader = DataLoader(testset, batch_size=32, shuffle=True)\n",
        "\n",
        "trainset_ = Xray_dataset(train_,root_dir,transform = data_transforms)\n",
        "train_loader_ = DataLoader(trainset_, batch_size=32, sampler=sampler)\n",
        "\n",
        "valset = Xray_dataset(val,root_dir,transform = data_transforms)\n",
        "val_loader = DataLoader(valset, batch_size=32, shuffle=True)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "num_classes = 3\n",
        "\n",
        "loaders = {\"train\": train_loader_,\n",
        "           \"test\": test_loader,\n",
        "           \"val\": val_loader}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWXUDXwj4Nra"
      },
      "source": [
        "# Training and testing the model Resnet50\n",
        "# On the same lines Resnet18 was also trained.\n",
        "\n",
        "model = torchvision.models.resnet58(pretrained = True, progress = True)\n",
        "model.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_model(20, loaders, model, optimizer, criterion,use_cuda, '/content/drive/MyDrive/sri model/resnet50_pretrained.pt')\n",
        "model = torch.load('/content/drive/MyDrive/sri model/resnet50_pretrained.pt')\n",
        "from sklearn.metrics import classification_report\n",
        "def conf_met(model,val_loader):\n",
        "    true = []\n",
        "    pred = []\n",
        "    test_loss = 0\n",
        "    model.cuda()\n",
        "    for img,tag in tqdm.tqdm(test_loader):\n",
        "        img = img.cuda()\n",
        "        op = model(img)\n",
        "        #loss = criterion(output, target)\n",
        "        #test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        pred+= list(op.data.max(1, keepdim=True)[1].cpu().squeeze().data.numpy())\n",
        "        true += list(tag.data.numpy())\n",
        "\n",
        "    print(f\"\\nConfusion Metrix : \\n{classification_report(true,pred)}\")\n",
        "conf_met(model,test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYFbSjk87JCW"
      },
      "source": [
        "# Preparing the images for experimentation\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images,label = dataiter.next()\n",
        "label = label+1\n",
        "images = images.cpu()\n",
        "\n",
        "imagessvp = images.cpu().detach().numpy()\n",
        "#imagessvp = np.swapaxes(imagessvp,2,3)\n",
        "imagessvp = np.swapaxes(imagessvp,1,2)\n",
        "imagessvp = np.swapaxes(imagessvp,2,3)\n",
        "imagessvp.shape\n",
        "fig,axes = plt.subplots(nrows = 12, ncols = 1, figsize=(25,75))\n",
        "\n",
        "for ax in axes.flatten():\n",
        "  ax.axis('off')\n",
        "k = 0\n",
        "for i in range(12):\n",
        "  for j in range(1):\n",
        "\n",
        "    axes[i].set_title(labl[k][0]+\" Probability: \"+str(round(probi[k][L[k][0]-1].item()*100,4))+\"%\"+\"\\n\"+labl[k][1]+\" Probability: \"+str(round(probi[k][L[k][1]-1].item()*100,4))+\"%\"+\"\\n\"+labl[k][2]+\" probability: \"+str(round(probi[k][L[k][2]-1].item()*100,4))+\"%\")\n",
        "    axes[i].imshow(imagessvp[k])\n",
        "    k=k+1\n",
        "\n",
        "# fig.savefig('/content/drive/MyDrive/SRI images/SRI FINAL FINAL IMAGES/submission_original_images2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVVOklvI7Tik"
      },
      "source": [
        "model.cpu()\n",
        "l = model(images)\n",
        "# l = l.detach().numpy()\n",
        "sm = torch.nn.Softmax()\n",
        "probi = sm(l)\n",
        "l = l.cpu().detach().numpy()\n",
        "L = np.argsort(-l, axis=1)\n",
        "L = L+1\n",
        "labl = [[]]\n",
        "for i in range(12):\n",
        "  for j in range(3):\n",
        "    labl[i].append(dict_[int(L[i][j])])\n",
        "  labl.append([])\n",
        "labl.pop()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HJiWp9X7ds7"
      },
      "source": [
        "# Implementing the Lime technique for normal images. Same can be done for covid and viral pneumonia images\n",
        "\n",
        "def batch_predict(images):\n",
        "    model.eval()\n",
        "    batch = torch.stack(tuple(preprocess_transform(i) for i in images), dim=0)\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    logits = model(batch)\n",
        "    return logits.detach().numpy()\n",
        "\n",
        "def get_pil_transform():\n",
        "  transf = transforms.Compose([\n",
        "      transforms.Resize((256, 256)),\n",
        "      transforms.CenterCrop(224)\n",
        "  ])\n",
        "  return transf\n",
        "\n",
        "def get_preprocess_transform():\n",
        "  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "  transf = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      normalize\n",
        "  ])\n",
        "  return transf\n",
        "\n",
        "pill_transf = get_pil_transform()\n",
        "preprocess_transform = get_preprocess_transform()\n",
        "\n",
        "def get_image(path):\n",
        "    with open(os.path.abspath(path), 'rb') as f:\n",
        "        with Image.open(f) as img:\n",
        "            return img.convert('RGB')\n",
        "from lime import lime_image\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "k = [11,12,13,14]\n",
        "i=0\n",
        "fig,axes = plt.subplots(nrows = len(k), ncols = 3,figsize=(25,25))\n",
        "for ax in axes.flatten():\n",
        "  ax.axis('off')\n",
        "for t in k:\n",
        "  from skimage.segmentation import mark_boundaries\n",
        "  explanation = explainer.explain_instance(imagessvp[t],\n",
        "                                          batch_predict, # classification function,\n",
        "                                          hide_color=0,\n",
        "                                          top_labels=2,\n",
        "                                          num_samples=2000)\n",
        "  temp1, mask1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=5, hide_rest=False)\n",
        "  img_boundry1 = mark_boundaries(temp1, mask1)\n",
        "  temp2, mask2 = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=False, num_features=5, hide_rest=False)\n",
        "  img_boundry2 = mark_boundaries(temp2, mask2)\n",
        "\n",
        "  axes[i,0].imshow(imagessvp[t])\n",
        "  axes[i,0].set_title(\"Original Image: \"+dict_[int(label[t].numpy())])\n",
        "  axes[i,1].set_title(\"Prediction: \"+labl[t][0])\n",
        "  axes[i,2].set_title(\"Second Prediction: \"+labl[t][1])\n",
        "  axes[i,1].imshow(img_boundry1)\n",
        "  axes[i,2].imshow(img_boundry2)\n",
        "  i=i+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1F5F4hw7uGr"
      },
      "source": [
        "#  Deconvolution, Saliency, Integrated Gradients, Occlusion, Lrp techniques code for covid images. Same can be done for normal and viral pneumonia images.\n",
        "\n",
        "!pip install captum\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import Deconvolution\n",
        "from captum.attr import Saliency\n",
        "from captum.attr import visualization as viz\n",
        "from captum.attr import Occlusion\n",
        "from captum.attr import GradientShap\n",
        "from captum.attr import DeepLift\n",
        "\n",
        "\n",
        "import captum.attr\n",
        "model = model.cuda()\n",
        "def attribute_image_features(algorithm, input,ind, **kwargs):\n",
        "    model.zero_grad()\n",
        "    tensor_attributions = algorithm.attribute(input,\n",
        "                                              target=label[ind],\n",
        "                                              **kwargs\n",
        "                                             )\n",
        "\n",
        "    return tensor_attributions\n",
        "\n",
        "\n",
        "i=0\n",
        "\n",
        "k = [0,1,2,3]\n",
        "fig,axes = plt.subplots(nrows = len(k), ncols = 6,figsize=(37.5,25))\n",
        "for ax in axes.flatten():\n",
        "  ax.axis('off')\n",
        "\n",
        "for ind in k:\n",
        "  input = images[ind].cuda().unsqueeze(0)\n",
        "  input.requires_grad = True\n",
        "  imagesvp = imagessvp[ind]\n",
        "\n",
        "  print(ind)\n",
        "  saliency = Saliency(model)\n",
        "  grads = saliency.attribute(input, target=label[ind]-1)\n",
        "  grads = np.transpose(grads.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
        "  print(ind,'sal')\n",
        "  deconv = Deconvolution(model)\n",
        "  gradd = deconv.attribute(input, target=label[ind]-1)\n",
        "  gradd = np.transpose(gradd.squeeze(0).cpu().detach().numpy(), (1, 2, 0))\n",
        "  print(ind,'dec')\n",
        "  lrp = captum.attr.LRP(model)\n",
        "  gradlrp = lrp.attribute(input, target=label[ind]-1)\n",
        "  gradlrp = np.transpose(gradlrp.squeeze(0).cpu().detach().numpy(), (1, 2, 0))\n",
        "  print(ind,'lrp')\n",
        "  ig = IntegratedGradients(model)\n",
        "  gradig = ig.attribute(input, target=label[ind]-1)\n",
        "  gradig = np.transpose(gradig.squeeze(0).cpu().detach().numpy(), (1, 2, 0))\n",
        "  print(ind,'ig')\n",
        "\n",
        "  #gradient_shap = GradientShap(model)\n",
        "  #gradshap = gradient_shap.attribute(input, baselines = input * 0,target=label[ind]-1)\n",
        "  #gradshap = np.transpose(gradshap.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
        "  #print(ind,'gs')\n",
        "  #lime = Lime(model)\n",
        "  #gradl = lime.attribute(input,target=label[ind]-1,n_samples=200)\n",
        "  #gradl = np.transpose(gradl.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
        "  #print(ind,'lime')\n",
        "\n",
        "  ablator = Occlusion(model)\n",
        "  #Computes occlusion attribution, ablating each 3x3 patch,\n",
        "  #shifting in each direction by the default of 1.\n",
        "  grado = ablator.attribute(input, target=label[ind]-1, sliding_window_shapes=(3,3,3))\n",
        "  grado = np.transpose(grado.squeeze().cpu().detach().numpy(), (1, 2, 0))\n",
        "\n",
        "\n",
        "  original_image = np.transpose((images[ind].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
        "\n",
        "  a = viz.visualize_image_attr(None, original_image, plt_fig_axis=(fig,axes[i,0]),\n",
        "                        method=\"original_image\", title=\"Original Image, Predicted: \"+labl[ind][0],use_pyplot=False)\n",
        "\n",
        "  _ = viz.visualize_image_attr(gradd, original_image, plt_fig_axis=(fig,axes[i,1]),method=\"blended_heat_map\",sign=\"absolute_value\",\n",
        "                              title=\"deconvolution\",show_colorbar=True,use_pyplot=False)\n",
        "  _ = viz.visualize_image_attr(grads, original_image, method=\"blended_heat_map\",show_colorbar=True,sign=\"absolute_value\",\n",
        "                              plt_fig_axis=(fig,axes[i,2]),title=\"saliency\",use_pyplot=False)\n",
        "  _ = viz.visualize_image_attr(gradlrp, original_image, method=\"heat_map\",show_colorbar=True,sign=\"all\",\n",
        "                              plt_fig_axis=(fig,axes[i,3]),title=\"Lrp\",use_pyplot=False)\n",
        " # _ = viz.visualize_image_attr(gradshap, original_image, method=\"blended_heat_map\",show_colorbar=True,sign=\"all\",\n",
        "  #                            plt_fig_axis=(fig,axes[i,4]),title=\"Grad Shap\",use_pyplot=False)\n",
        "  #_ = viz.visualize_image_attr(gradl, original_image, method=\"blended_heat_map\",show_colorbar=True,sign=\"all\",\n",
        "   #                             plt_fig_axis=(fig,axes[i,5]),title=\"Grad Lime\",use_pyplot=False)\n",
        "  _ = viz.visualize_image_attr(grado, original_image, method=\"blended_heat_map\",show_colorbar=True,sign=\"all\",\n",
        "                              plt_fig_axis=(fig,axes[i,4]),title=\"Occlusion\",use_pyplot = False)\n",
        "  _ = viz.visualize_image_attr(gradig, original_image, method=\"blended_heat_map\",show_colorbar=True,sign=\"all\",\n",
        "                              plt_fig_axis=(fig,axes[i,5]),title=\"Integrated Gradients\",use_pyplot = False)\n",
        "  i = i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BRTRiwy75tL"
      },
      "source": [
        "# Gradcam++ code for covid images.\n",
        "# Same can be done for AblationCam and Xgradcam by changing the fucntions.\n",
        "\n",
        "# !pip install grad-cam\n",
        "# !pip install ttach\n",
        "# from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n",
        "# from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "i=0\n",
        "k = [11,12,13,14]\n",
        "fig,axes = plt.subplots(nrows = len(k), ncols = 4,figsize = (25,25))\n",
        "for ax in axes.flatten():\n",
        "    ax.axis('off')\n",
        "i=0\n",
        "for ind in k:\n",
        "  imagevp = imagessvp[ind]\n",
        "  norm = (imagevp - np.min(imagevp)) / (np.max(imagevp) - np.min(imagevp))\n",
        "  target_layer = model.layer4[-1]\n",
        "  cam = GradCAMPlusPlus(model=model.cpu(), target_layer=target_layer)\n",
        "  grayscale_cam = cam(images[ind].unsqueeze(0), target_category=0)\n",
        "  grayscal_cam = grayscale_cam[0,:]\n",
        "  visualization1 = show_cam_on_image(norm, grayscal_cam)\n",
        "\n",
        "\n",
        "  cam = GradCAMPlusPlus(model=model, target_layer=target_layer)\n",
        "  grayscale_cam = cam(images[ind].unsqueeze(0), target_category=1)\n",
        "  grayscal_cam = grayscale_cam[0,:]\n",
        "  visualization2 = show_cam_on_image(norm, grayscal_cam)\n",
        "\n",
        "  cam = GradCAMPlusPlus(model=model, target_layer=target_layer)\n",
        "  grayscale_cam = cam(images[ind].unsqueeze(0), target_category=2)\n",
        "  grayscal_cam = grayscale_cam[0,:]\n",
        "  visualization3 = show_cam_on_image(norm, grayscal_cam)\n",
        "\n",
        "\n",
        "\n",
        "  vis = [visualization1,visualization2,visualization3]\n",
        "  tit = ['Gradcam++ Covid Areas','Gradcam++ Normal Areas','Gradcam++ Viral Pneumonia Areas']\n",
        "  axes[i,0].set_title('Original Image, Predicted: '+labl[ind][0])\n",
        "  original_image = np.transpose((images[ind].cpu().detach().numpy() / 2) + 0.5, (1, 2, 0))\n",
        "  axes[i,0].imshow(original_image)\n",
        "  q=1\n",
        "  for d in L[ind]:\n",
        "    axes[i,q].set_title(tit[d-1])\n",
        "    axes[i,q].imshow(vis[d-1])\n",
        "    q=q+1\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}